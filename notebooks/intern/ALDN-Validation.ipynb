{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed96f4bc-65c9-4829-92d6-feda3be34d61",
   "metadata": {},
   "source": [
    "# Validating Alaska Lightning Probability Model\n",
    "\n",
    "In this notebook you will learn:\n",
    "\n",
    "- how to visualize model output data\n",
    "- how to perform quick statistics and exploratory data analysis\n",
    "- how to get model metrics for validation\n",
    "\n",
    "For this part of the work we will be looking at outputs from the trained model on ALDN data. We will look at the model performance under:\n",
    "\n",
    "- general conditions\n",
    "- per biome\n",
    "- per severity day\n",
    "- per temporal window.\n",
    "\n",
    "You will use the base code from the previous notebook to finish the last three plots from this notebook. I have provided examples below on how you can query the data and use it to plot.\n",
    "\n",
    "## 1. Open database to work with\n",
    "\n",
    "We will use a database to validate our model. This database includes observations across all dates, biomes, and temporal windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e3536-6bac-4161-84ff-041548783fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055714d-78e4-41f5-b31b-ac75f2404863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from huggingface_hub import snapshot_download\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, \\\n",
    "    classification_report, brier_score_loss, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd58b9-7d9f-4150-81e4-0a1e3828800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'jordancaraballo/alaska-lightning'\n",
    "DATASET_FILENAME = 'validation/validation-alaska.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d477982-14e3-4934-a1a3-4e9b4cb26f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#database_filename = '/explore/nobackup/people/jacaraba/development/wildfire-occurrence/notebooks/validation-alaska.gpkg'\n",
    "alaska_dataset = snapshot_download(repo_id=DATASET_URL, allow_patterns=\"*.gpkg\", repo_type='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c73377-3b26-4048-9a33-0a0f316fda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_filename = os.path.join(alaska_dataset, DATASET_FILENAME)\n",
    "database_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db6340-e160-41aa-b94e-3eda42a600dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_database = gpd.read_file(database_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e479f6-49f7-4c23-ab37-4b9110e18047",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_database.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc1c27-2caa-4b90-83d9-adec66d2ed24",
   "metadata": {},
   "source": [
    "## 2. Basic Accuracy Metrics - Biome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec204672-1b09-4f9c-8fc0-f2b5999079d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(df):\n",
    "    conf_matrix = confusion_matrix(df['Label'], df['predictions'])\n",
    "    a = conf_matrix[0][0]\n",
    "    b = conf_matrix[0][1]\n",
    "    c = conf_matrix[1][0]\n",
    "    d = conf_matrix[1][1]\n",
    "\n",
    "    print(\"Accuracy: \", accuracy_score(df['Label'], df['predictions']))\n",
    "    print(\"POD:      \", a / (a+c))\n",
    "    print(\"CSI:      \", a / (a+b+c))\n",
    "    print(\"FAR:      \", b / (a+c))\n",
    "    print(\"F:        \", b / (b+d))\n",
    "    print(\"Brier:    \", brier_score_loss(df['Label'], df['predictions_proba']))\n",
    "    print(\"Log Loss: \", log_loss(df['Label'], df['predictions_proba']))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492c182-db3d-4492-bbff-8d12c1163509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Accuracy, Alaska\n",
    "print_accuracy(validation_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c75e6-d9b5-4533-b23b-41a624760fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Accuracy, Tundra\n",
    "tundra = validation_database[validation_database['BIOME'] == 'TUNDRA']\n",
    "print_accuracy(tundra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33521010-140a-48e6-ba0b-c226dc6e43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Accuracy, Boreal\n",
    "boreal = validation_database[validation_database['BIOME'] == 'BOREAL']\n",
    "print_accuracy(boreal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e906f-8b71-41b6-91a4-bcd6d0e208c4",
   "metadata": {},
   "source": [
    "## 3. Basic Accuracy Metrics - Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b0bcc-e40f-4827-81db-cf34783fdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Accuracy, Severe\n",
    "severe = validation_database[validation_database['Severity2'] == 'Severe']\n",
    "print_accuracy(severe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553d006-2541-4eb4-a39b-004aed223b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Accuracy, Moderate\n",
    "moderate = validation_database[validation_database['Severity2'] == 'Moderate']\n",
    "print_accuracy(moderate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19afd24b-6b23-46aa-8d61-a4fa80ebf16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Accuracy, Low\n",
    "low = validation_database[validation_database['Severity2'] == 'Low']\n",
    "print_accuracy(low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f2304-bbf0-4cda-8420-edd8ce71f486",
   "metadata": {},
   "source": [
    "## Example plot - which dates are we performing the worst?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62dc58c-d9ab-4b6a-8d40-f27cf08b9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_points = validation_database[validation_database['Label'] != validation_database['predictions']]\n",
    "ax = failed_points.WRFDATE_STR.value_counts().sort_index().plot(\n",
    "    kind='barh', title='Least Accurate Days for Model Performance')\n",
    "ax.set_xlabel(\"Count of Failed Classification Points\")\n",
    "ax.set_ylabel(\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e96ef8-826f-49b1-9735-0cb7ba86921d",
   "metadata": {},
   "source": [
    "## Example plot - which dates are we performing the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af868a-aa09-47ce-b9e0-6d57fdab1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate_points = validation_database[validation_database['Label'] == validation_database['predictions']]\n",
    "ax = accurate_points.WRFDATE_STR.value_counts().sort_index().plot(\n",
    "    kind='barh', title='Most Accurate Days for Model Performance')\n",
    "ax.set_xlabel(\"Count of True Classification Points\")\n",
    "ax.set_ylabel(\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958978f-4f41-4dbd-862a-c5744f417c3e",
   "metadata": {},
   "source": [
    "The pattern between these two seems to be related to the number of points available. It would be interesting to understand if there are any climate variables driving this difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea7b0c-91b6-4610-a234-e92b25b9177a",
   "metadata": {},
   "source": [
    "## 4. Task #1: Generate Bar Plot with Accuracy per Location (Boreal vs Tundra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835460d-7149-430b-876c-aa2be5ab66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert your code Here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada1e57-e506-4fac-aeef-4f5ad48e1c72",
   "metadata": {},
   "source": [
    "## 5. Task #2: Generate Bar Plot with Accuracy per Severity Level (Severe, Moderate, Low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfa154-cc4d-4d36-88ca-2d0ca0d9320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert your code Here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aaf36a-da87-4770-ac20-253915497f0b",
   "metadata": {},
   "source": [
    "## 6. Task #3: Generate Map to Illustrate where our model fails the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546a83b-6be1-4cda-ba9c-33a8d0a9b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert your code Here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f63b7-c52c-4882-a9ff-05322424a8f4",
   "metadata": {},
   "source": [
    "## 7. Task #4: Write three conclusions from the results listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac929b0-45c7-4e36-9e2e-718f1ba7752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert your text Here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcff74-83a2-4d7b-981e-b2aaf5753474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel (Pytorch)",
   "language": "python",
   "name": "pytorch-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
